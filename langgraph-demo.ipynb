{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f83702d4",
   "metadata": {},
   "source": [
    "# Smart News Analyzer & Fact Checker\n",
    "\n",
    "**LangGraph + Gemini 2.5 Flash Demo** (No LangChain)\n",
    "\n",
    "This notebook demonstrates:\n",
    "- **LangGraph state machine** with multiple nodes and conditional edges\n",
    "- **Gemini 2.5 Flash** for text analysis and claim extraction\n",
    "- **Gemini Google Search tool** for real-time fact verification\n",
    "- **Human-in-the-loop** interrupts for uncertain claims\n",
    "- **Failure recovery** (bad URL ‚Üí ask user to paste text)\n",
    "- **SQLite checkpoints** for state persistence\n",
    "- **LangSmith tracing** for observability in Studio\n",
    "\n",
    "## How to run\n",
    "\n",
    "1. Start LangGraph Studio in terminal: `langgraph dev`\n",
    "2. Run all cells below\n",
    "3. Use the Gradio chat interface to analyze news articles\n",
    "4. Watch the graph execute in LangSmith Studio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d241b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä LangSmith tracing enabled for project: smart-news-analyzer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Configure LangSmith tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"smart-news-analyzer\"\n",
    "\n",
    "print(\"\\nüìä LangSmith tracing enabled for project: smart-news-analyzer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b88c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßµ Thread ID: session-d9d8e5e5\n",
      "   (Save this ID to resume from checkpoints after kernel restart)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import uuid\n",
    "from smart_news_graph import get_graph_with_checkpointer, Command\n",
    "from langgraph.types import Command\n",
    "\n",
    "graph = get_graph_with_checkpointer()\n",
    "\n",
    "# Generate a unique thread ID for this session (or reuse one for recovery)\n",
    "THREAD_ID = f\"session-{uuid.uuid4().hex[:8]}\"\n",
    "print(f\"üßµ Thread ID: {THREAD_ID}\")\n",
    "print(\"   (Save this ID to resume from checkpoints after kernel restart)\")\n",
    "\n",
    "# Store pending interrupt info\n",
    "pending_interrupt = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa1e7ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Graph runner functions loaded\n"
     ]
    }
   ],
   "source": [
    "# Helper functions for running the graph with interrupt handling\n",
    "\n",
    "def run_graph_step(user_input: str, thread_id: str = None):\n",
    "    \"\"\"\n",
    "    Run the graph with user input. Handles interrupts gracefully.\n",
    "    Returns: (response_text, is_complete, interrupt_info)\n",
    "    \"\"\"\n",
    "    global pending_interrupt\n",
    "    thread_id = thread_id or THREAD_ID\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    # Check if we're resuming from an interrupt\n",
    "    if pending_interrupt:\n",
    "        try:\n",
    "            result = graph.invoke(Command(resume=user_input), config)\n",
    "            pending_interrupt = None\n",
    "        except Exception as e:\n",
    "            return f\"Error resuming: {str(e)}\", False, None\n",
    "    else:\n",
    "        # Fresh run\n",
    "        initial_state = {\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": user_input}]\n",
    "        }\n",
    "        try:\n",
    "            result = graph.invoke(initial_state, config)\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\", False, None\n",
    "    \n",
    "    # Check if we hit an interrupt\n",
    "    state = graph.get_state(config)\n",
    "    \n",
    "    if state.next:\n",
    "        # Graph is paused at an interrupt\n",
    "        # Look for interrupt info in the state's tasks\n",
    "        for task in state.tasks:\n",
    "            if hasattr(task, 'interrupts') and task.interrupts:\n",
    "                interrupt_data = task.interrupts[0]\n",
    "                pending_interrupt = interrupt_data.value\n",
    "                return pending_interrupt.get(\"message\", \"Awaiting input...\"), False, pending_interrupt\n",
    "        \n",
    "        pending_interrupt = {\"type\": \"unknown\", \"message\": f\"Paused at: {state.next}\"}\n",
    "        return f\"‚è∏Ô∏è Graph paused at: {state.next}. Provide input to continue.\", False, pending_interrupt\n",
    "    \n",
    "    # Graph completed\n",
    "    final_report = result.get(\"final_report\", \"No report generated\")\n",
    "    \n",
    "    # Build summary\n",
    "    summary_parts = []\n",
    "    \n",
    "    if result.get(\"article_title\"):\n",
    "        summary_parts.append(f\"üì∞ **Article:** {result['article_title']}\")\n",
    "    \n",
    "    if result.get(\"claims\"):\n",
    "        summary_parts.append(f\"\\nüìã **Claims extracted:** {len(result['claims'])}\")\n",
    "    \n",
    "    if result.get(\"verifications\"):\n",
    "        summary_parts.append(\"\\nüîç **Verification Results:**\")\n",
    "        for v in result[\"verifications\"]:\n",
    "            emoji = {\"verified\": \"‚úÖ\", \"false\": \"‚ùå\", \"uncertain\": \"‚ùì\", \"needs_review\": \"‚ö†Ô∏è\"}.get(v[\"verdict\"], \"‚Ä¢\")\n",
    "            summary_parts.append(f\"  {emoji} {v['claim'][:60]}...\")\n",
    "    \n",
    "    if result.get(\"sentiment\"):\n",
    "        s = result[\"sentiment\"]\n",
    "        summary_parts.append(f\"\\nüí≠ **Sentiment:** {s.get('label', 'unknown')} (score: {s.get('compound', 0):.2f})\")\n",
    "    \n",
    "    summary_parts.append(f\"\\n\\n---\\n\\n## üìä Final Report\\n\\n{final_report}\")\n",
    "    \n",
    "    return \"\\n\".join(summary_parts), True, None\n",
    "\n",
    "\n",
    "print(\"‚úÖ Graph runner functions loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583e16d",
   "metadata": {},
   "source": [
    "## Checkpoint Recovery Demo\n",
    "\n",
    "LangGraph uses SQLite checkpoints to persist state. If the kernel crashes or you restart:\n",
    "\n",
    "1. Note your `THREAD_ID` from above\n",
    "2. Restart kernel\n",
    "3. Run cells 1-3\n",
    "4. Set `THREAD_ID = \"your-saved-thread-id\"` \n",
    "5. Run the cell below to see saved state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12af34e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Run inspect_checkpoint() to view saved state\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint inspection - View current state from SQLite checkpoint\n",
    "\n",
    "def inspect_checkpoint(thread_id: str = None):\n",
    "    \"\"\"Inspect the current checkpoint state for a thread.\"\"\"\n",
    "    thread_id = thread_id or THREAD_ID\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    try:\n",
    "        state = graph.get_state(config)\n",
    "        \n",
    "        print(f\"üîç Checkpoint State for thread: {thread_id}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        if state.values:\n",
    "            print(f\"\\nüìå Current state values:\")\n",
    "            for key, value in state.values.items():\n",
    "                if isinstance(value, list) and len(value) > 2:\n",
    "                    print(f\"   {key}: [{len(value)} items]\")\n",
    "                elif isinstance(value, str) and len(value) > 100:\n",
    "                    print(f\"   {key}: {value[:100]}...\")\n",
    "                else:\n",
    "                    print(f\"   {key}: {value}\")\n",
    "            \n",
    "            print(f\"\\n‚è≠Ô∏è Next nodes: {state.next}\")\n",
    "            \n",
    "            if state.next:\n",
    "                print(\"\\n‚ö†Ô∏è Graph is paused - waiting for input to resume\")\n",
    "        else:\n",
    "            print(\"No checkpoint found for this thread.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading checkpoint: {e}\")\n",
    "\n",
    "# inspect_checkpoint()\n",
    "print(\"üíæ Run inspect_checkpoint() to view saved state\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027923fd",
   "metadata": {},
   "source": [
    "## Gradio Chat Interface\n",
    "\n",
    "The chat UI below allows you to:\n",
    "- **Paste a URL** to a news article (the graph will fetch and analyze it)\n",
    "- **Paste article text** directly if the URL fails or you prefer\n",
    "- **Respond to interrupts** when the agent needs human input\n",
    "- **See the graph visualization** in LangSmith Studio (running in terminal)\n",
    "\n",
    "### Test scenarios:\n",
    "1. **Normal flow**: Paste a real news URL (e.g., from BBC, CNN, Reuters)\n",
    "2. **Failure + recovery**: Paste a fake URL like `https://fake-news-site.com/article` \n",
    "3. **Human-in-the-loop**: The agent will ask for your input on uncertain claims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8806aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ldr0/Documents/UPM/Cloud Computing/langchainPresentation/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/_3/7nx89wtj68x77c5zlhz5fztm0000gn/T/ipykernel_17575/1270978293.py:29: UserWarning: The parameters have been moved from the Blocks constructor to the launch() method in Gradio 6.0: theme. Please pass these parameters to launch() instead.\n",
      "  with gr.Blocks(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradio Chat Interface\n",
    "import gradio as gr\n",
    "\n",
    "def chat_handler(message: str, history: list):\n",
    "    \"\"\"\n",
    "    Handle chat messages. Runs the graph and handles interrupts.\n",
    "    \"\"\"\n",
    "    global pending_interrupt\n",
    "    \n",
    "    if not message.strip():\n",
    "        return \"Please enter a news article URL or paste article text.\"\n",
    "    \n",
    "    # Run the graph step\n",
    "    response, is_complete, interrupt_info = run_graph_step(message.strip())\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "def reset_session():\n",
    "    \"\"\"Reset the session for a fresh analysis.\"\"\"\n",
    "    global THREAD_ID, pending_interrupt\n",
    "    import uuid\n",
    "    THREAD_ID = f\"session-{uuid.uuid4().hex[:8]}\"\n",
    "    pending_interrupt = None\n",
    "    return f\"üîÑ Session reset. New thread ID: {THREAD_ID}\"\n",
    "\n",
    "\n",
    "# Create the Gradio interface\n",
    "with gr.Blocks(\n",
    "    title=\"Smart News Analyzer\",\n",
    "    theme=gr.themes.Soft(\n",
    "        primary_hue=\"blue\",\n",
    "        secondary_hue=\"slate\",\n",
    "    )\n",
    ") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üì∞ Smart News Analyzer & Fact Checker\n",
    "    \n",
    "    **Powered by LangGraph + Gemini 2.5 Flash**\n",
    "    \n",
    "    Paste a news article URL or text to analyze. The agent will:\n",
    "    1. Extract key claims\n",
    "    2. Verify each claim using Google Search\n",
    "    3. Ask for your input on uncertain claims\n",
    "    4. Generate a fact-check report\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            # FIX: Removed 'type=\"messages\"' but we will still send dictionaries below\n",
    "            chatbot = gr.Chatbot(\n",
    "                height=500,\n",
    "                show_label=False,\n",
    "                avatar_images=(None, \"https://em-content.zobj.net/source/twitter/376/robot_1f916.png\"),\n",
    "            )\n",
    "            \n",
    "            msg = gr.Textbox(\n",
    "                placeholder=\"Paste a news article URL or text here...\",\n",
    "                show_label=False,\n",
    "                container=False,\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                submit_btn = gr.Button(\"Analyze\", variant=\"primary\")\n",
    "                reset_btn = gr.Button(\"New Session\", variant=\"secondary\")\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(f\"\"\"\n",
    "            ### Session Info\n",
    "            \n",
    "            **Thread ID:** `{THREAD_ID}`\n",
    "            \n",
    "            ### Instructions\n",
    "            \n",
    "            1. Paste URL or article text\n",
    "            2. Click \"Analyze\"\n",
    "            3. Respond to any prompts\n",
    "            4. View report when complete\n",
    "            \n",
    "            ### Watch in Studio\n",
    "            \n",
    "            Run `langgraph dev` in terminal\n",
    "            to see the graph execute!\n",
    "            \"\"\")\n",
    "            \n",
    "            status_box = gr.Textbox(\n",
    "                label=\"Status\",\n",
    "                value=\"Ready\",\n",
    "                interactive=False,\n",
    "            )\n",
    "    \n",
    "    def respond(message, chat_history):\n",
    "        if not message.strip():\n",
    "            return \"\", chat_history\n",
    "        \n",
    "        # 1. User message as DICTIONARY\n",
    "        chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        # 2. Get Response\n",
    "        response_text = chat_handler(message, chat_history)\n",
    "        \n",
    "        # 3. Assistant message as DICTIONARY\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": response_text})\n",
    "        \n",
    "        return \"\", chat_history\n",
    "    \n",
    "    # Connect inputs\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "    submit_btn.click(respond, [msg, chatbot], [msg, chatbot])\n",
    "    \n",
    "    # Reset button\n",
    "    reset_btn.click(\n",
    "        lambda: ([], reset_session()),\n",
    "        outputs=[chatbot, status_box]\n",
    "    )\n",
    "\n",
    "# Launch the interface\n",
    "demo.launch(share=False, inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
